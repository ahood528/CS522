{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n!pip install minisom\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom minisom import MiniSom\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-09T20:58:41.544677Z","iopub.execute_input":"2022-12-09T20:58:41.545094Z","iopub.status.idle":"2022-12-09T20:58:54.803442Z","shell.execute_reply.started":"2022-12-09T20:58:41.545018Z","shell.execute_reply":"2022-12-09T20:58:54.802322Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting minisom\n  Downloading MiniSom-2.3.0.tar.gz (8.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: minisom\n  Building wheel for minisom (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for minisom: filename=MiniSom-2.3.0-py3-none-any.whl size=9018 sha256=6992a985fe3a6b0272143fee80a2ce51b7ae07c423c3e047b5427708889a0f4f\n  Stored in directory: /root/.cache/pip/wheels/d4/ca/4a/488772b0399fec45ff53132ed14c948dec4b30deee3a532f80\nSuccessfully built minisom\nInstalling collected packages: minisom\nSuccessfully installed minisom-2.3.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m/kaggle/input/runclustering/RunScores.csv\n/kaggle/input/runclustering/consolidated.csv\n/kaggle/input/runclustering/RouteUnitCoordinates.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The goal is to load up the run scores and dates, produce a list of lists, the sublist is the score for that time index.\nThen the data is normalized, then it's run through a Self-Organizing Map for clustering.\nThen we have to save the results of clustering for use later.","metadata":{}},{"cell_type":"code","source":"#scales 1, 6, 18?\ndef scaleCallingIndexes(lst) :\n    #print(\"lst\",lst)\n    acc = 0\n    acc += (1 * lst[0])\n    acc += (6 * lst[1])\n    acc += (18 * lst[2])\n    return acc\n    \n# step 1 is to load and parse the run scores\nrunscores = pd.read_csv('../input/runclustering/RunScores.csv')\nrunscoreDict = {}\nfor index,row in runscores.iterrows() :\n    newkey = row['RunID']\n    newvalue = scaleCallingIndexes([row['1'], row['2'], row['3']])\n    if newvalue is None :\n        print(\"that didn't work\")\n        break\n    runscoreDict[newkey] = newvalue\n\nfailedtransform = 0\n\ndef transformConsolidatedRow(row,route,year) :\n    scorelist = []\n    datelist = []\n    finallist = []\n    global failedtransform\n    global runscoreDict\n    if row['RunID1'] in runscoreDict :\n        scorelist.append(runscoreDict[row['RunID1']])\n        datelist.append(round(row['OrdinalDate1']))\n    if row['RunID2'] in runscoreDict :\n        scorelist.append(runscoreDict[row['RunID2']])\n        datelist.append(round(row['OrdinarlDate2'])) # spelling mistake in input csv\n    if row['RunID3'] in runscoreDict :\n        scorelist.append(runscoreDict[row['RunID3']])\n        datelist.append(round(row['OrdinalDate3']))\n    if row['RunID4'] in runscoreDict :\n        scorelist.append(runscoreDict[row['RunID4']])\n        datelist.append(round(row['OrdinalDate4']))\n    # numpy only does linear interpolation if the points are monotonically increasing, which I suppose we could do if we do it piecewise and reverse it if it's going the wrong way?\n    numPieces = len(scorelist) - 1\n    if numPieces == 0 :  # there is no data for run 283, the whole row should not be in consolidated.csv.  It's in Runs.csv but not Counts.csv.  So it's not in RunScores.csv\n        #print(\"zero pieces\",route,year)\n        failedtransform += 1\n        return None\n    if numPieces < 0 :\n        #print(\"negative pieces\", route, year) # one row had no data for any of the three runs\n        failedtransform += 1\n        return None\n    for x in range(numPieces) :\n        #print(\"x is\",x,\"len scorelist\",len(scorelist),\"len runscoreDict\",len(runscoreDict),scorelist)\n        rise = scorelist[x+1] - scorelist[x]\n        run = datelist[x+1] - datelist[x]\n        finallist.append(scorelist[x])\n        day = 1\n        for y in range(datelist[x]+1, datelist[x+1]) :\n            finallist.append(scorelist[x]+((day/run)*rise))\n            day += 1\n    finallist.append(scorelist[numPieces])\n    if len(finallist) != 61 :\n        # print(len(finallist),route,year,\"uh oh, list not the right length\",finallist) # this is due to missing data as well AFAICT\n        failedtransform += 1\n        return None\n    return finallist\n    \n# step 2, load and parse the consolidated data\nconsolidated = pd.read_csv('../input/runclustering/consolidated.csv')\nrouteThenYear = {}\nattempts = 0\nfor index, row in consolidated.iterrows() :\n    route = str(row['RouteNumber'])\n    year = str(row['SurveyYear'])\n    # initialize if non-existent\n    if route not in routeThenYear :\n        routeThenYear[route] = {}\n    if year not in routeThenYear[route] :\n        attempts += 1\n        traret = transformConsolidatedRow(row,route,year)\n        if traret :\n            routeThenYear[route][year] = traret\n    #print(route,year,routeThenYear[route][year])\n    #break\ngoodvalues = 0\nfor key, value in routeThenYear.items() :\n    goodvalues = goodvalues + len(value)\nprint(\"failedtransform\",failedtransform,'good values',goodvalues,'attempts',attempts)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T20:58:54.805578Z","iopub.execute_input":"2022-12-09T20:58:54.806880Z","iopub.status.idle":"2022-12-09T20:58:58.043054Z","shell.execute_reply.started":"2022-12-09T20:58:54.806831Z","shell.execute_reply":"2022-12-09T20:58:58.041097Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"failedtransform 379 good values 5739 attempts 6118\n","output_type":"stream"}]},{"cell_type":"code","source":"# now we have to normalize the data to use in clustering\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\n#skipOuter = 3\n#skipOuterCounter = 0\nnormalindex = 0\nnormalizedScoresOverTime = []\nrouteList = []\nyearList = []\nfor key, value in routeThenYear.items() :\n    for k2, v2 in value.items() : # dictionary of years mapped to 61-element lists\n        llv2 = []\n        for x in v2 : # each element has to be turned into a list\n            llv2.append([x])\n        t2 = MinMaxScaler().fit_transform(llv2)\n        t2 = t2.reshape(len(t2))\n        normalizedScoresOverTime.append(t2)\n        routeList.append(key)\n        yearList.append(k2)\n        normalindex += 1\n        #print(len(v2), len(llv2), len(t2))\n        #print(v2)\n        #print(llv2)\n        #print(t2)\n        #break\n    #break\nprint(\"done normalizing\",normalindex)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T20:58:58.045102Z","iopub.execute_input":"2022-12-09T20:58:58.045764Z","iopub.status.idle":"2022-12-09T20:58:59.735042Z","shell.execute_reply.started":"2022-12-09T20:58:58.045702Z","shell.execute_reply":"2022-12-09T20:58:59.733194Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"done normalizing 5739\n","output_type":"stream"}]},{"cell_type":"code","source":"# now we can run minisom\nmap_side_length = 40\nasom = MiniSom(map_side_length, map_side_length, len(normalizedScoresOverTime[0]))\nasom.random_weights_init(normalizedScoresOverTime)\nasom.train(normalizedScoresOverTime, 50000)\nprint(\"training done\")\n# need to write all this to a file so we can run association analysis\nxlist = []\nylist = []\nfor x in normalizedScoresOverTime :\n    (xwin, ywin) = asom.winner(x)\n    xlist.append(xwin)\n    ylist.append(ywin)\noutDataFrame = pd.DataFrame({\n    'RouteNumber': routeList,\n    'SurveyYear': yearList,\n    'x': xlist,\n    'y': ylist})\noutDataFrame.to_csv('frogWinners.csv')\n# print out scores to see if dense enough\nfor (row,column), value  in asom.win_map(normalizedScoresOverTime).items() :\n    print(row,column,len(value))","metadata":{"execution":{"iopub.status.busy":"2022-12-09T21:10:54.482591Z","iopub.execute_input":"2022-12-09T21:10:54.482964Z","iopub.status.idle":"2022-12-09T21:11:18.512068Z","shell.execute_reply.started":"2022-12-09T21:10:54.482934Z","shell.execute_reply":"2022-12-09T21:11:18.511144Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"training done\n4 10 5\n3 7 8\n23 36 7\n10 39 10\n39 35 3\n4 8 9\n5 14 5\n9 0 3\n5 36 5\n0 33 295\n30 27 10\n23 11 10\n5 35 7\n16 24 8\n30 2 6\n7 16 8\n34 39 9\n23 9 4\n13 11 7\n3 35 7\n30 22 4\n10 4 5\n6 1 7\n21 13 5\n16 26 8\n20 11 7\n19 11 7\n9 7 12\n18 9 6\n8 17 6\n35 10 7\n36 27 9\n29 26 12\n35 29 11\n13 20 8\n9 22 7\n38 27 6\n8 2 4\n0 3 10\n24 3 7\n12 18 8\n11 1 2\n0 8 10\n11 3 5\n34 24 11\n18 8 9\n17 20 6\n37 6 2\n14 30 2\n14 12 4\n38 3 3\n11 10 17\n29 21 3\n11 13 5\n25 22 8\n34 33 1\n13 8 6\n12 13 5\n38 22 8\n39 3 5\n21 37 7\n20 22 238\n37 8 4\n4 19 4\n8 25 5\n8 21 5\n10 28 4\n0 0 7\n26 29 4\n16 1 5\n27 26 5\n3 20 5\n7 39 5\n0 27 5\n5 13 7\n5 17 2\n2 9 2\n3 15 5\n1 16 7\n6 10 3\n6 8 4\n11 14 3\n7 37 6\n0 18 6\n4 27 2\n24 38 3\n18 16 2\n1 13 5\n2 29 7\n0 15 6\n4 12 8\n9 36 3\n17 2 8\n22 32 5\n2 17 2\n10 37 10\n3 18 4\n26 20 2\n28 19 9\n22 33 8\n29 23 5\n14 13 10\n24 1 6\n26 28 2\n33 31 4\n3 33 4\n36 19 2\n0 11 4\n27 33 6\n4 13 4\n37 0 3\n9 38 12\n2 18 4\n5 12 4\n10 38 7\n8 39 9\n2 16 7\n25 16 4\n6 14 5\n25 20 5\n28 14 2\n0 13 5\n0 16 7\n17 21 4\n4 18 3\n5 15 7\n21 29 5\n10 36 6\n8 37 5\n8 38 5\n4 14 5\n11 37 5\n3 11 6\n0 14 8\n6 7 6\n1 12 4\n6 12 8\n3 14 7\n1 14 9\n21 7 7\n2 30 4\n12 11 9\n13 10 8\n13 13 6\n22 31 5\n27 17 5\n23 38 8\n0 26 5\n23 17 5\n0 38 7\n4 28 3\n4 24 6\n2 13 6\n13 25 6\n35 23 11\n6 38 4\n17 16 6\n15 22 5\n24 28 2\n18 14 1\n11 12 10\n9 29 5\n9 12 4\n10 10 5\n3 39 4\n17 5 3\n11 21 3\n24 24 8\n26 1 3\n37 3 2\n3 28 5\n28 16 4\n39 4 2\n37 25 7\n10 9 11\n29 12 9\n4 37 5\n25 28 5\n29 9 3\n10 22 5\n11 29 4\n17 14 6\n3 30 5\n1 11 8\n11 24 3\n21 2 3\n30 37 2\n4 30 8\n0 35 6\n10 23 2\n6 21 9\n11 28 4\n2 35 8\n22 29 5\n5 28 7\n10 12 9\n36 38 10\n5 31 6\n19 9 8\n17 26 8\n8 29 7\n11 11 11\n12 8 9\n22 0 8\n17 34 6\n14 8 4\n35 36 4\n8 36 9\n5 6 7\n23 27 5\n9 37 4\n5 7 5\n16 6 3\n16 3 6\n13 36 5\n32 28 13\n17 27 5\n20 35 7\n27 18 7\n10 20 8\n20 5 6\n39 33 12\n1 25 5\n39 8 5\n10 11 6\n34 4 4\n10 30 4\n10 18 6\n14 34 5\n21 9 6\n2 26 5\n11 8 9\n16 11 4\n24 32 3\n35 33 7\n7 0 5\n26 26 4\n8 16 7\n37 1 3\n8 30 5\n39 22 9\n16 12 4\n13 39 4\n13 38 7\n1 30 6\n37 15 2\n4 35 8\n11 18 10\n14 22 4\n1 24 6\n1 34 6\n3 3 4\n9 17 9\n13 12 5\n36 21 5\n0 37 4\n34 25 5\n22 12 6\n12 0 5\n13 30 4\n12 10 8\n8 8 8\n24 26 3\n21 39 5\n0 29 5\n15 13 5\n16 32 2\n27 6 6\n9 4 7\n26 32 6\n30 1 7\n4 36 9\n37 13 8\n29 25 6\n36 12 5\n24 22 4\n19 10 8\n27 32 4\n38 23 6\n32 25 7\n4 9 7\n6 35 3\n8 26 4\n39 6 4\n6 30 6\n39 39 7\n7 24 6\n24 37 4\n17 13 4\n22 24 2\n17 17 2\n31 1 7\n1 0 4\n7 36 3\n9 8 8\n34 26 5\n5 11 3\n2 25 7\n25 17 4\n29 18 5\n3 10 8\n16 7 7\n1 6 5\n26 27 6\n37 20 3\n25 27 2\n9 39 9\n6 11 8\n7 28 3\n22 11 8\n21 8 8\n17 9 3\n6 31 2\n28 1 3\n7 19 7\n8 24 7\n21 10 7\n15 4 3\n17 18 7\n11 16 9\n13 19 12\n8 28 4\n2 3 8\n1 15 8\n13 14 10\n27 28 5\n39 28 12\n15 12 3\n33 0 9\n18 18 3\n5 29 4\n33 5 3\n36 10 4\n38 31 6\n9 10 8\n0 1 7\n35 39 9\n13 35 7\n21 12 9\n15 35 7\n3 0 11\n9 6 4\n0 20 5\n4 4 7\n34 27 4\n37 31 6\n29 34 9\n0 10 3\n17 4 4\n0 21 7\n29 8 5\n7 23 4\n20 1 6\n2 2 8\n26 2 7\n4 38 3\n39 24 10\n6 0 7\n36 25 4\n11 17 9\n1 37 2\n13 9 4\n22 19 6\n13 6 7\n39 36 4\n24 13 8\n25 2 4\n3 23 6\n25 3 8\n13 23 4\n29 10 5\n24 12 7\n19 27 6\n11 6 5\n39 32 7\n32 16 6\n15 25 8\n15 30 2\n0 24 6\n4 39 3\n10 14 3\n14 32 6\n10 7 8\n22 9 5\n22 13 5\n38 11 4\n14 33 7\n13 26 10\n15 37 2\n12 23 8\n19 7 6\n16 27 9\n37 22 9\n17 11 4\n27 21 5\n37 10 9\n30 26 10\n17 24 7\n20 10 10\n31 28 17\n31 27 8\n13 24 4\n17 10 6\n20 13 4\n31 34 10\n29 0 11\n12 21 5\n31 24 10\n4 31 3\n0 6 5\n16 5 4\n18 36 7\n11 20 7\n17 25 7\n31 26 10\n9 21 3\n5 4 8\n30 34 7\n36 39 10\n36 14 5\n14 0 5\n32 15 4\n30 18 11\n21 0 3\n24 2 6\n19 26 4\n26 19 5\n35 26 7\n18 27 4\n5 23 5\n14 21 9\n11 19 14\n23 10 4\n0 39 6\n4 0 3\n37 39 11\n0 7 12\n12 28 5\n2 19 5\n34 36 6\n24 17 3\n30 15 3\n35 24 4\n14 23 11\n26 9 7\n27 34 7\n31 25 6\n39 7 5\n19 25 6\n1 28 6\n19 8 6\n5 24 8\n37 30 7\n37 32 6\n11 4 6\n31 13 3\n3 34 3\n30 4 5\n16 4 2\n39 14 7\n6 23 5\n6 20 6\n8 19 14\n32 26 6\n32 36 3\n36 15 4\n10 24 6\n17 29 2\n30 13 4\n23 37 8\n20 25 5\n27 23 6\n31 36 5\n4 3 7\n8 23 7\n2 33 9\n32 24 6\n38 21 8\n35 1 5\n39 21 11\n32 13 1\n26 0 6\n26 16 4\n31 2 3\n29 35 10\n8 4 8\n31 12 5\n28 2 1\n32 18 2\n33 4 3\n6 6 5\n20 3 6\n25 7 6\n29 16 4\n11 23 4\n13 34 4\n30 19 8\n34 9 5\n33 9 6\n30 23 6\n32 11 6\n38 14 3\n16 36 3\n1 5 9\n19 38 3\n7 1 9\n20 12 5\n31 37 4\n20 38 6\n5 0 8\n23 16 9\n13 3 9\n36 9 3\n39 23 9\n39 19 2\n12 17 7\n3 4 5\n7 17 4\n27 14 5\n9 16 8\n16 23 6\n10 19 6\n35 11 3\n1 7 8\n14 24 1\n9 3 6\n37 38 11\n19 5 5\n25 34 5\n4 1 9\n14 38 4\n14 39 4\n27 0 6\n5 3 14\n30 28 7\n32 14 3\n18 25 3\n9 18 10\n3 1 10\n32 23 3\n32 10 3\n24 11 9\n10 13 8\n13 22 6\n9 14 5\n15 27 3\n12 20 12\n37 36 5\n19 35 7\n13 4 11\n25 18 1\n13 0 4\n1 27 3\n12 4 8\n38 33 6\n34 38 6\n4 34 2\n26 6 4\n39 25 10\n36 11 7\n23 26 3\n27 7 7\n1 38 2\n30 24 12\n15 17 5\n29 28 3\n23 13 5\n37 4 2\n27 22 8\n21 11 4\n37 33 8\n5 34 3\n11 2 5\n36 35 11\n39 10 7\n21 4 4\n1 21 5\n24 27 3\n20 39 2\n8 12 3\n9 19 11\n7 2 5\n13 21 8\n18 39 3\n29 13 3\n3 27 3\n9 30 4\n23 24 4\n27 19 5\n6 13 3\n20 14 2\n4 11 9\n21 3 3\n2 34 7\n20 26 1\n3 36 1\n28 17 5\n26 31 4\n12 22 5\n20 36 5\n23 3 6\n32 2 4\n38 29 9\n32 5 3\n37 35 7\n25 0 10\n31 31 2\n22 3 10\n20 8 6\n24 6 4\n18 2 2\n23 31 5\n34 11 3\n18 26 3\n1 39 4\n10 3 8\n15 34 2\n36 28 2\n22 4 10\n33 16 5\n16 37 4\n8 33 4\n34 14 2\n17 12 3\n26 38 2\n34 13 2\n31 39 5\n21 36 2\n7 34 3\n22 2 1\n35 13 1\n4 22 1\n14 36 4\n14 10 3\n37 11 1\n14 15 1\n15 11 3\n38 25 1\n28 38 2\n30 30 3\n14 17 1\n35 12 1\n8 20 5\n13 17 2\n11 33 4\n14 27 5\n30 39 3\n32 20 1\n8 7 3\n35 35 8\n15 5 2\n3 8 10\n32 39 2\n0 28 6\n24 25 4\n3 17 6\n33 35 7\n23 18 5\n26 39 2\n18 37 1\n12 3 1\n23 0 6\n10 34 1\n10 33 3\n13 33 1\n7 3 4\n9 33 3\n22 30 4\n25 15 3\n12 32 2\n30 38 2\n11 32 2\n39 26 1\n14 26 3\n11 31 3\n35 15 2\n15 18 4\n12 26 1\n24 16 3\n10 6 1\n7 31 2\n10 8 7\n35 20 4\n33 17 3\n8 1 6\n1 17 5\n18 10 6\n24 23 3\n38 7 7\n21 32 4\n25 25 3\n38 36 5\n21 1 2\n19 39 3\n38 10 4\n12 19 9\n38 12 4\n26 3 9\n21 38 2\n4 6 6\n35 9 7\n10 1 6\n7 26 7\n29 22 5\n28 15 7\n25 9 7\n25 1 4\n20 4 6\n39 9 5\n9 20 8\n28 0 4\n34 10 4\n15 24 7\n20 27 5\n19 4 3\n4 23 6\n12 1 3\n0 5 9\n31 22 3\n10 16 6\n17 6 5\n1 29 7\n8 3 4\n11 9 11\n2 4 3\n8 0 4\n13 2 3\n38 6 8\n37 27 3\n35 25 5\n26 5 3\n29 1 9\n38 13 4\n24 0 4\n36 24 7\n7 18 4\n29 17 3\n39 13 3\n9 2 5\n33 11 6\n39 30 6\n38 8 5\n33 10 6\n12 39 10\n1 3 6\n13 1 5\n12 35 2\n16 0 2\n18 29 3\n36 1 5\n35 28 6\n21 5 5\n20 9 5\n6 3 1\n22 1 3\n34 23 3\n37 16 1\n11 5 4\n39 29 3\n6 24 6\n9 1 3\n8 10 9\n21 35 4\n28 36 3\n2 10 5\n10 21 5\n22 18 3\n37 29 5\n32 1 7\n28 9 5\n9 9 7\n7 20 3\n24 39 2\n3 19 5\n34 3 5\n25 35 6\n26 25 4\n36 20 3\n18 12 2\n33 30 5\n4 33 2\n27 16 2\n36 36 8\n27 3 5\n29 2 7\n27 1 3\n32 27 7\n24 34 9\n0 34 1\n23 23 6\n39 12 6\n29 32 2\n10 32 4\n32 17 4\n19 12 5\n8 11 1\n12 12 1\n9 15 1\n31 14 1\n3 26 1\n39 16 1\n22 39 2\n30 16 7\n8 18 5\n14 25 6\n3 31 1\n25 23 9\n39 0 5\n16 25 8\n16 28 4\n0 32 1\n37 7 3\n23 12 5\n20 2 3\n35 3 3\n2 15 3\n3 16 5\n3 13 7\n22 15 3\n31 4 3\n38 30 2\n34 15 2\n18 28 1\n30 31 1\n32 37 2\n19 36 2\n22 17 4\n27 38 1\n29 30 2\n25 6 4\n35 7 2\n32 38 2\n28 18 6\n13 15 4\n30 29 2\n33 14 2\n28 31 3\n7 4 3\n5 22 2\n7 33 2\n15 10 2\n35 14 2\n18 38 2\n11 34 3\n25 4 1\n9 11 7\n29 27 2\n1 33 6\n11 22 3\n25 26 5\n29 15 6\n25 19 4\n32 0 3\n19 13 3\n37 9 5\n13 29 3\n27 29 6\n5 1 5\n23 25 3\n38 4 3\n39 31 11\n28 23 3\n10 2 3\n5 21 6\n7 25 3\n37 26 5\n36 26 4\n28 22 4\n27 2 2\n12 2 4\n12 14 4\n3 38 2\n38 16 1\n11 26 1\n18 11 4\n6 34 1\n35 30 4\n11 0 4\n5 10 6\n20 20 3\n38 9 3\n21 21 3\n35 5 3\n22 8 7\n39 11 3\n34 2 1\n12 9 4\n10 17 3\n34 1 6\n33 36 7\n7 21 2\n6 29 7\n35 21 6\n6 18 1\n36 0 7\n8 9 6\n3 9 9\n15 26 7\n14 19 2\n6 26 7\n25 37 3\n34 5 3\n36 31 4\n20 0 4\n1 18 3\n20 32 2\n14 20 3\n15 36 3\n10 5 1\n29 24 2\n33 22 1\n23 1 5\n6 25 5\n36 29 2\n34 28 3\n25 5 4\n26 8 5\n10 0 3\n23 4 2\n23 32 4\n30 0 5\n23 6 5\n17 0 3\n6 9 4\n22 26 2\n35 0 5\n22 10 6\n38 28 4\n24 35 3\n32 30 6\n6 19 3\n20 37 2\n38 0 3\n30 25 6\n23 35 6\n29 4 3\n31 0 2\n20 30 5\n24 15 3\n26 15 2\n15 3 5\n5 8 5\n37 28 5\n4 26 7\n30 8 2\n16 10 2\n38 1 3\n16 13 2\n3 12 2\n38 32 4\n38 35 2\n18 13 1\n34 35 4\n2 14 2\n29 5 2\n19 37 2\n28 21 3\n33 18 2\n24 36 4\n27 5 3\n26 18 3\n22 16 2\n14 35 1\n33 1 3\n24 7 3\n35 27 4\n17 3 3\n36 30 3\n4 29 5\n25 8 4\n17 1 3\n18 20 4\n7 38 3\n33 2 5\n4 15 6\n26 14 1\n30 9 3\n1 36 1\n25 39 2\n39 1 1\n36 16 1\n22 5 2\n29 31 3\n0 22 2\n28 32 2\n21 16 2\n16 38 2\n30 5 2\n32 4 1\n30 32 4\n23 20 1\n7 29 2\n27 27 7\n31 5 2\n21 33 3\n27 31 1\n18 17 4\n21 15 2\n2 27 4\n30 17 2\n5 16 2\n5 33 1\n7 30 3\n0 12 1\n23 15 3\n4 16 4\n12 24 1\n21 18 4\n0 25 3\n18 15 2\n2 32 1\n26 7 3\n24 29 4\n9 32 2\n11 25 1\n33 15 1\n27 37 2\n35 38 4\n30 12 1\n19 32 2\n29 19 5\n2 28 3\n5 9 2\n14 1 2\n19 20 1\n26 17 2\n33 32 4\n0 17 5\n12 6 2\n19 21 1\n27 25 4\n28 10 4\n5 20 1\n19 14 3\n30 10 2\n35 2 3\n19 31 3\n27 15 3\n12 29 2\n14 29 1\n1 26 3\n15 7 1\n4 7 1\n8 22 1\n8 34 2\n15 21 1\n25 36 2\n35 17 1\n9 13 3\n20 16 3\n25 29 2\n6 39 2\n21 31 3\n33 3 3\n21 30 2\n20 31 1\n5 30 1\n16 33 3\n27 36 2\n28 39 1\n10 25 1\n15 6 3\n14 16 5\n15 16 1\n25 24 1\n7 22 1\n12 33 2\n37 12 2\n13 16 1\n18 1 1\n26 37 2\n6 22 1\n31 23 1\n26 36 1\n10 31 1\n19 16 1\n3 29 1\n16 2 3\n21 17 1\n6 28 1\n25 38 1\n3 37 2\n8 32 1\n20 7 1\n1 22 1\n24 4 1\n23 19 1\n23 2 1\n","output_type":"stream"}]}]}