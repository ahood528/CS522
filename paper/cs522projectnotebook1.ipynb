{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e46a0fa",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-11-26T20:51:54.683728Z",
     "iopub.status.busy": "2022-11-26T20:51:54.682959Z",
     "iopub.status.idle": "2022-11-26T20:51:54.711552Z",
     "shell.execute_reply": "2022-11-26T20:51:54.709454Z"
    },
    "papermill": {
     "duration": 0.038284,
     "end_time": "2022-11-26T20:51:54.714763",
     "exception": false,
     "start_time": "2022-11-26T20:51:54.676479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cs522-paper/Runs.csv\n",
      "/kaggle/input/cs522-paper/Counts.csv\n",
      "/kaggle/input/cs522-paper/Stops.csv\n",
      "/kaggle/input/cs522-paper/Coordinates.csv\n",
      "cwd  /kaggle/working\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        \n",
    "print(\"cwd \", os.getcwd())\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb8f370e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T20:51:54.724184Z",
     "iopub.status.busy": "2022-11-26T20:51:54.723338Z",
     "iopub.status.idle": "2022-11-26T20:51:56.619814Z",
     "shell.execute_reply": "2022-11-26T20:51:56.618210Z"
    },
    "papermill": {
     "duration": 1.904857,
     "end_time": "2022-11-26T20:51:56.623130",
     "exception": false,
     "start_time": "2022-11-26T20:51:54.718273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loopCounter 12064 coordDict 1183\n",
      "(1183, 3)\n"
     ]
    }
   ],
   "source": [
    "# find the average of a list of numbers\n",
    "def avgList(lst):\n",
    "    acc = 0\n",
    "    for elt in lst :\n",
    "        acc += elt\n",
    "    return acc / len(lst)\n",
    "    \n",
    "# determine coordinates for each route unit\n",
    "csvpd = pd.read_csv('../input/cs522-paper/Coordinates.csv')\n",
    "coordDict = {}\n",
    "RTNUM = 'RouteNumber'\n",
    "LAT = 'lat'\n",
    "LON = 'lon'\n",
    "loopCounter = 0\n",
    "# for each row\n",
    "for index, row in csvpd.iterrows() :\n",
    "    loopCounter += 1\n",
    "    # if the route number is in the dictionary\n",
    "    if row[RTNUM] in coordDict :\n",
    "        # extract the pair list\n",
    "        coordListPair = coordDict[row[RTNUM]]\n",
    "        # add the new coordinates to the pair list\n",
    "        coordListPair[LAT].append(row[LAT])\n",
    "        coordListPair[LON].append(row[LON])\n",
    "    else :\n",
    "        # the route number is not in the dictionary\n",
    "        coordListPair = {}\n",
    "        # initialize the data structure\n",
    "        coordListPair[LAT] = []\n",
    "        coordListPair[LON] = []\n",
    "        # insert it into the dictionary\n",
    "        coordDict[row[RTNUM]] = coordListPair\n",
    "# create frame for output\n",
    "frameOut = pd.DataFrame(columns=[RTNUM, LAT, LON])\n",
    "# for each route number, find the average coordinates\n",
    "for key, value in coordDict.items() :\n",
    "    latAvg = avgList(value[LAT])\n",
    "    lonAvg = avgList(value[LON])\n",
    "    series1 = pd.Series({RTNUM : key, LAT : latAvg, LON : lonAvg})\n",
    "    frameOut = pd.concat([frameOut, series1.to_frame().T], ignore_index=True)\n",
    "print(\"loopCounter\",loopCounter,\"coordDict\",len(coordDict))\n",
    "print(frameOut.shape)\n",
    "frameOut.head()\n",
    "frameOut.to_csv('RouteUnitCoordinates.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf7519bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T20:51:56.632384Z",
     "iopub.status.busy": "2022-11-26T20:51:56.631910Z",
     "iopub.status.idle": "2022-11-26T20:52:47.837420Z",
     "shell.execute_reply": "2022-11-26T20:52:47.835683Z"
    },
    "papermill": {
     "duration": 51.213652,
     "end_time": "2022-11-26T20:52:47.840475",
     "exception": false,
     "start_time": "2022-11-26T20:51:56.626823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "(21406, 4)\n"
     ]
    }
   ],
   "source": [
    "# compute scores for each run\n",
    "countscsv = pd.read_csv('../input/cs522-paper/Counts.csv')\n",
    "RUNID = 'RunID'\n",
    "CALLINGINDEX='CallingIndex'\n",
    "# count unique calling index to check\n",
    "countscsv[CALLINGINDEX].unique()\n",
    "# create output data struct\n",
    "runscore = {}\n",
    "# for each row\n",
    "for index, row in countscsv.iterrows() :\n",
    "    # if the run id is in the dictionary\n",
    "    if row[RUNID] in runscore :\n",
    "        # get the list of calling index scores\n",
    "        scoreDict = runscore[row[RUNID]]\n",
    "        # get the calling index for this row\n",
    "        callingindex = row[CALLINGINDEX]\n",
    "        # increment the number of times this calling index has been seen in this run id\n",
    "        scoreDict[callingindex] += 1\n",
    "    else :\n",
    "        # the run id is not in the dictionary\n",
    "        scoreDict = {}\n",
    "        # initialize\n",
    "        scoreDict[1] = 0\n",
    "        scoreDict[2] = 0\n",
    "        scoreDict[3] = 0\n",
    "        # insert\n",
    "        runscore[row[RUNID]] = scoreDict\n",
    "# create frame for output\n",
    "frameOut2 = pd.DataFrame(columns=[RUNID, \"1\", \"2\", \"3\"])\n",
    "loopCounter = 0\n",
    "for key, value in runscore.items() :\n",
    "    loopCounter += 1\n",
    "    series2 = pd.Series({RUNID : key, \"1\" : value[1], \"2\" : value[2], \"3\" : value[3]})\n",
    "    frameOut2 = pd.concat([frameOut2,series2.to_frame().T], ignore_index=True)\n",
    "    if (loopCounter % 1000) == 0 :\n",
    "        print(loopCounter)\n",
    "print(frameOut2.shape)\n",
    "frameOut2.head()\n",
    "frameOut2.to_csv(\"RunScores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd40eedf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T20:52:47.852004Z",
     "iopub.status.busy": "2022-11-26T20:52:47.851403Z",
     "iopub.status.idle": "2022-11-26T20:52:48.225847Z",
     "shell.execute_reply": "2022-11-26T20:52:48.224265Z"
    },
    "papermill": {
     "duration": 0.383985,
     "end_time": "2022-11-26T20:52:48.229102",
     "exception": false,
     "start_time": "2022-11-26T20:52:47.845117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        3\n",
      "1        4\n",
      "8        1\n",
      "29       5\n",
      "31       2\n",
      "46       6\n",
      "69       7\n",
      "106      8\n",
      "2560    10\n",
      "4945     9\n",
      "5845    12\n",
      "Name: SurveyDate, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# we need to find the months in which surveys take place, ah ha, some are in december of the previous calendar year\n",
    "# using the survey date and run number columns an regex in Notepad++, the only surveys which start in the previous calendar year start in December\n",
    "surveydate='SurveyDate'\n",
    "runscsv = pd.read_csv('../input/cs522-paper/Runs.csv', parse_dates=[surveydate])\n",
    "surveydates = runscsv[surveydate]\n",
    "months = (surveydates.dt.month).drop_duplicates()\n",
    "print(months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2c08422",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T20:52:48.241398Z",
     "iopub.status.busy": "2022-11-26T20:52:48.240906Z",
     "iopub.status.idle": "2022-11-26T20:52:50.262199Z",
     "shell.execute_reply": "2022-11-26T20:52:50.260248Z"
    },
    "papermill": {
     "duration": 2.031412,
     "end_time": "2022-11-26T20:52:50.265364",
     "exception": false,
     "start_time": "2022-11-26T20:52:48.233952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done1 7678\n",
      "done2 1560\n",
      "2001,510503,1,0,136,2,34.8,177,3,60.0,197,,,\n",
      "\n",
      "2001,211101,1,0,137,2,26.129032258064516,179,3,60.0,192,,,\n",
      "\n",
      "2001,460503,1,0,138,2,28.314606741573034,304,3,60.0,305,,,\n",
      "\n",
      "2001,460203,1,0,139,2,34.285714285714285,9825,3,60.0,262,,,\n",
      "\n",
      "2001,460704,1,0,141,2,31.304347826086957,321,3,60.0,9681,,,\n",
      "\n",
      "2001,460708,1,0,9730,2,29.690721649484537,9731,3,60.0,9732,,,\n",
      "\n",
      "2001,460505,1,0,143,2,20.666666666666664,309,3,60.0,310,,,\n",
      "\n",
      "2001,211102,1,0,145,2,29.18918918918919,785,3,60.0,243,,,\n",
      "\n",
      "2001,420211,1,0,146,2,24.17910447761194,147,3,60.0,189,,,\n",
      "\n",
      "2001,420311,1,0,153,2,17.00787401574803,148,3,60.0,208,,,\n",
      "\n",
      "2001,420316,1,0,149,2,17.00787401574803,150,3,60.0,209,,,\n",
      "\n",
      "2001,420310,1,0,151,2,39.25233644859813,214,3,59.99999999999999,225,,,\n",
      "\n",
      "2001,420411,1,0,152,2,23.149606299212596,219,3,60.0,218,,,\n",
      "\n",
      "2001,420312,1,0,154,2,23.243243243243246,155,3,60.0,296,,,\n",
      "\n",
      "2001,420210,1,0,156,2,20.0,223,3,60.0,224,,,\n",
      "\n",
      "2001,420110,1,0,157,2,18.52941176470588,220,3,60.0,227,,,\n",
      "\n",
      "2001,420516,1,0,158,2,31.42857142857143,221,3,60.0,222,,,\n",
      "\n",
      "2001,420412,1,0,159,2,23.142857142857142,160,3,60.0,250,,,\n",
      "\n",
      "2001,211001,1,0,162,2,21.875,171,3,60.0,207,,,\n",
      "\n",
      "2001,210902,1,0,163,2,24.615384615384617,247,3,60.0,248,,,\n",
      "\n",
      "2001,460706,1,0,167,2,33.78151260504202,206,3,60.0,328,,,\n",
      "\n",
      "2001,210801,1,0,168,2,22.758620689655174,254,3,60.00000000000001,255,,,\n",
      "\n",
      "2001,420111,1,0,211,2,34.95652173913044,213,3,60.0,187,,,\n",
      "\n",
      "2001,420511,1,0,212,2,34.95652173913044,191,3,60.0,188,,,\n",
      "\n",
      "2001,211202,1,0,200,2,35.45454545454545,201,3,59.99999999999999,202,,,\n",
      "\n",
      "2001,210702,1,0,231,2,15.384615384615385,230,3,60.0,232,,,\n",
      "\n",
      "2001,490519,1,0,234,2,36.33802816901408,235,3,60.0,236,,,\n",
      "\n",
      "2001,460107,1,0,9722,2,28.333333333333336,9721,3,60.0,9724,,,\n",
      "\n",
      "2001,490420,1,0,249,2,31.636363636363633,251,3,59.99999999999999,252,,,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use the scores and run metadata to create series out of the runs, each series belongs to a route and a year, worse, to make a time series, they have to be of uniform length\n",
    "# using 60/61 time units, we need to convert each run date to the ordinal day, make a new column in the data frame with that\n",
    "# I've confirmed there are only four unique numbers for RunNumber, so if I just start counting down I'll hit the largest run number and make that one equal to 60\n",
    "TIME_UNITS = 60\n",
    "ORDINAL_DATE = 'ORDINAL_DATE'\n",
    "SURVEY_YEAR = 'SurveyYear'\n",
    "ROUTE_NUMBER = \"RouteNumber\"\n",
    "RUN_NUMBER = 'RunNumber'\n",
    "runscsv[ORDINAL_DATE] = surveydates.dt.day_of_year\n",
    "#print(runscsv[ORDINAL_DATE].drop_duplicates()) #check if the operation seems to work as intended\n",
    "\n",
    "# iterate through each row, building up the dictionary of runs for a given pair of survey year and route number\n",
    "# each element of the dictionary of runs should be a pair, the run id and the ordinal day of the year, and indexed by the run number\n",
    "deletedFromLackOfRuns = 0\n",
    "surveyyear_routenumber = {}\n",
    "for index, row in runscsv.iterrows() :\n",
    "    # create the key\n",
    "    key_syrn = str(str(row[SURVEY_YEAR]) + str(row[ROUTE_NUMBER]))\n",
    "    if key_syrn not in surveyyear_routenumber :\n",
    "        surveyyear_routenumber[key_syrn] = dict([('year', row[SURVEY_YEAR]), ('route', row[ROUTE_NUMBER]), ('runs', {}), ('norm', {})])\n",
    "        #if row[RUN_NUMBER] in surveyyear_routenumber[key_syrn]['runs'] :\n",
    "            #print (\"very unexpected, assert? throw? I dunno\", index, key_syrn, row[RUN_NUMBER])\n",
    "    #else :\n",
    "        # initialize the dictionary for this \n",
    "        #surveyyear_routenumber[key_syrn] = dict([('year', row[SURVEY_YEAR]), ('route', row[ROUTE_NUMBER]), ('runs', {})])\n",
    "    # record the day of the year for this run\n",
    "    surveyyear_routenumber[key_syrn]['runs'][row[RUN_NUMBER]] = (row[ORDINAL_DATE], row[RUNID])\n",
    "print(\"done1\", len(surveyyear_routenumber))\n",
    "# normalize dates to range 0-60\n",
    "for key, value in surveyyear_routenumber.items() :\n",
    "    runs = value['runs']\n",
    "    #print(runs)\n",
    "    handleCases = True\n",
    "    # handle case where we only have one run\n",
    "    if len(runs) == 1 :\n",
    "        deletedFromLackOfRuns += 1\n",
    "        handleCases = False\n",
    "        del value['runs']\n",
    "        continue\n",
    "    # handle the case where we're lacking run number 1\n",
    "    if 1 not in runs and handleCases and 2 in runs:\n",
    "        deletedFromLackOfRuns += 1\n",
    "        handleCases = False\n",
    "        del value['runs']\n",
    "        continue\n",
    "        #runs[1] = runs[2]\n",
    "        #runs[2] = runs[3]\n",
    "        #if 4 in runs :\n",
    "        #    runs[3] = runs[4]\n",
    "        #    del runs[4]\n",
    "        #else :\n",
    "        #    del runs[3]\n",
    "    # handle missing 1 and 2\n",
    "    if 1 not in runs and handleCases and 2 not in runs :\n",
    "        deletedFromLackOfRuns += 1\n",
    "        handleCases = False\n",
    "        del value['runs']\n",
    "        continue\n",
    "        #runs[1] = runs[3]\n",
    "        #runs[2] = runs[4]\n",
    "        #del runs[3]\n",
    "        #del runs[4]\n",
    "    # handle missing run number 2\n",
    "    if 2 not in runs and handleCases:\n",
    "        deletedFromLackOfRuns += 1\n",
    "        handleCases = False\n",
    "        del value['runs']\n",
    "        continue\n",
    "        #runs[2] = runs[3]\n",
    "        #del runs[3]\n",
    "        #if 4 in runs :\n",
    "        #    runs[3] = runs[4]\n",
    "        #    del runs[4]\n",
    "    # extract the run numbers\n",
    "    (a,b) = runs[1] # (ordinal, run id)\n",
    "    (c,d) = runs[2] if 2 in runs else (False, False)\n",
    "    (e,f) = runs[3] if 3 in runs else (False, False)\n",
    "    # handle case where the first date is in the previous calendar year, the month of which is only December\n",
    "    (g,h) = runs[4] if 4 in runs else (False, False)\n",
    "    if c and a > c :\n",
    "        if c :\n",
    "            c = c + 365\n",
    "        if e :\n",
    "            e = e + 365\n",
    "        if g :\n",
    "            g = g + 365\n",
    "    # figure out the range of dates, normalize them to start at 0\n",
    "    runrange = 0\n",
    "    rangefactor = 1\n",
    "    if g :\n",
    "        runrange = g - a\n",
    "    elif e :\n",
    "        runrange = e - a\n",
    "    else :\n",
    "        if c :\n",
    "            runrange = c - a\n",
    "    if runrange > 0 :\n",
    "        rangefactor = 60.0 / runrange    \n",
    "    if c :\n",
    "        c = c - a\n",
    "    if e :\n",
    "        e = e - a\n",
    "    if g :\n",
    "        g = g - a\n",
    "    a = 0\n",
    "    # normalize them to fit between 0 and 60\n",
    "    if c :\n",
    "        c = c * rangefactor\n",
    "    if e :\n",
    "        e = e * rangefactor\n",
    "    if g :\n",
    "        g = g * rangefactor\n",
    "    # put them back into the dictionary\n",
    "    runs[1] = (a,b)\n",
    "    if c :\n",
    "        runs[2] = (c,d)\n",
    "    if e :\n",
    "        runs[3] = (e,f)\n",
    "    if g :\n",
    "        runs[4] = (g,h)\n",
    "print(\"done2\",deletedFromLackOfRuns)\n",
    "# now we need to put this dictionary in a form we can use later\n",
    "# create .csv for writing\n",
    "f = open(\"consolidated.csv\", \"wb\")\n",
    "# write csv headers\n",
    "f.write(\"SurveyYear,RouteNumber,RunNumber1,OrdinalDate1,RunID1,RunNumber2,OrdinarlDate2,RunID2,RunNumber3,OrdinalDate3,RunID3,RunNumber4,OrdinalDate4,RunID4\\n\".encode())\n",
    "# loop through dict\n",
    "tempcnt = 0\n",
    "for key, value in surveyyear_routenumber.items() :\n",
    "    if 'runs' in value :\n",
    "        stracc = str(value['year']) + ','\n",
    "        stracc += (str(value['route']) + ',')\n",
    "        runs = value['runs']\n",
    "        if 1 in runs :\n",
    "            (ord, runid) = runs[1]\n",
    "            stracc += (\"1,\" + str(ord) + \",\" + str(runid) + \",\")\n",
    "        else :\n",
    "            stracc += \",,,\"\n",
    "        if 2 in runs :\n",
    "            (ord, runid) = runs[2]\n",
    "            stracc += (\"2,\" + str(ord) + \",\" + str(runid) + \",\")\n",
    "        else :\n",
    "            stracc += \",,,\"\n",
    "        if 3 in runs :\n",
    "            (ord, runid) = runs[3]\n",
    "            stracc += (\"3,\" + str(ord) + \",\" + str(runid) + \",\")\n",
    "        else :\n",
    "            stracc += \",,,\"\n",
    "        if 4 in runs :\n",
    "            (ord, runid) = runs[4]\n",
    "            stracc += (\"4,\" + str(ord) + \",\" + str(runid) + \"\\n\")\n",
    "        else :\n",
    "            stracc += \",,\\n\"\n",
    "        f.write(stracc.encode())\n",
    "        tempcnt += 1\n",
    "        if tempcnt < 30 :\n",
    "            print(stracc)\n",
    "# finished writing, close file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a22a380f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-26T20:52:50.277387Z",
     "iopub.status.busy": "2022-11-26T20:52:50.276921Z",
     "iopub.status.idle": "2022-11-26T20:52:50.291323Z",
     "shell.execute_reply": "2022-11-26T20:52:50.289823Z"
    },
    "papermill": {
     "duration": 0.023773,
     "end_time": "2022-11-26T20:52:50.294309",
     "exception": false,
     "start_time": "2022-11-26T20:52:50.270536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['consolidated.csv',\n",
       " '__notebook__.ipynb',\n",
       " 'RunScores.csv',\n",
       " 'RouteUnitCoordinates.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need a function to create scores, except no I don't because the files aren't accessible unless you Save Version and run the whole thing\n",
    "#def runscorer(scale1, scale2, scale3) :\n",
    "#    scorecsv = pd.read_csv('RunScores.csv')\n",
    "#    scorecsv['1'] = scorecsv['1'].apply(lambda x : x * scale1)\n",
    "#    scorecsv.to_csv('RunScoreTotal.csv', index=False)\n",
    "#    print(scorecsv.head())\n",
    "#runscorer(2,1,1)\n",
    "#print(os.getcwd())\n",
    "os.listdir(os.getcwd())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 67.007249,
   "end_time": "2022-11-26T20:52:51.325016",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-26T20:51:44.317767",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
